<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elixir Dataflows on Azrea Amis</title><link>/projects/flows/</link><description>Recent content in Elixir Dataflows on Azrea Amis</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright><lastBuildDate>Sat, 13 Oct 2018 12:36:21 -0700</lastBuildDate><atom:link href="/projects/flows/index.xml" rel="self" type="application/rss+xml"/><item><title>Flows the Wrong Way, Part 2: The Right Way</title><link>/posts/2018/10/13/flows-the-wrong-way-part-2-the-right-way/</link><pubDate>Sat, 13 Oct 2018 12:36:21 -0700</pubDate><guid>/posts/2018/10/13/flows-the-wrong-way-part-2-the-right-way/</guid><description>&lt;p>Note in 2022: I&amp;rsquo;m in a very different state of mind compared to when I wrote
this, and neither part represents my modern voice or style particularly well.
I think it&amp;rsquo;s still a good story.&lt;/p>
&lt;p>In my &lt;a href="/posts/2018-10-10-flows-the-wrong-way/">last post&lt;/a>, I covered my first attempt to implement TCP streaming in
&lt;code>Flow&lt;/code>, a data flow library for Elixir. My first attempts involved a bunch of
failed Unix sockets, and an attempt to implement a &lt;code>GenStage&lt;/code> that failed for
reasons I didn&amp;rsquo;t understand. I eventually settled on this:&lt;/p></description></item><item><title>Flows the Wrong Way: Streaming into Elixir</title><link>/posts/2018/10/10/flows-the-wrong-way-streaming-into-elixir/</link><pubDate>Wed, 10 Oct 2018 15:41:01 -0700</pubDate><guid>/posts/2018/10/10/flows-the-wrong-way-streaming-into-elixir/</guid><description>Note in 2022: I&amp;rsquo;m in a very different state of mind compared to when I wrote this, and neither part represents my modern voice or style particularly well. I think it&amp;rsquo;s still a good story.
As part of a new and exciting project, I was faced with the task of ingesting a large amount of more or less homogeneous JSON data into a SQL database for an associate of mine to do some rudimentary business intelligence analysis on it.</description></item></channel></rss>